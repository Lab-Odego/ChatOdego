{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependency"
      ],
      "metadata": {
        "id": "Ifum5IJ6xGSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmKnSOLTxA-a"
      },
      "outputs": [],
      "source": [
        "!pip install flask --quiet\n",
        "!pip install flask-ngrok --quiet\n",
        "!pip install pyngrok --quiet\n",
        "!pip install openai --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install sentence_transformers --quiet\n",
        "!pip install faiss-cpu --quiet\n",
        "!pip install tiktoken --quiet\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz --quiet\n",
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount at GoogleDrive"
      ],
      "metadata": {
        "id": "er-oSKbDxj15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd /content/drive/MyDrive/jinwoo/\n",
        "ROOT_PATH = \"/content/drive/MyDrive/jinwoo/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2_Ao32ixjXU",
        "outputId": "310f87e8-b589-40ec-dbd9-18c724ab02f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/jinwoo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# openAI API Key"
      ],
      "metadata": {
        "id": "2SGe2HP52eIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "with open(ROOT_PATH+'keys.txt', 'r') as f:\n",
        "    OPEN_API_KEY = f.readline()\n",
        "    # NGROK_AUTH_KEY = f.readline()\n",
        "\n",
        "openai.api_key = OPEN_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPEN_API_KEY"
      ],
      "metadata": {
        "id": "zImvyb0ZxoNR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import FAISS, Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader, DirectoryLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper"
      ],
      "metadata": {
        "id": "8yCiz_nOxpbc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM chat & Vector Index"
      ],
      "metadata": {
        "id": "CcexKpYd2pPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.9)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "fdb = FAISS.load_local(folder_path = ROOT_PATH+\"faiss-nj\",\n",
        "                       embeddings = embeddings)\n",
        "\n",
        "index = VectorStoreIndexWrapper(vectorstore = fdb)"
      ],
      "metadata": {
        "id": "YqmB4iJly0QE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flask App"
      ],
      "metadata": {
        "id": "ms9-5dQe2lK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import requests\n",
        "import json\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/chatbot', methods = ['POST'])\n",
        "def chatbot():\n",
        "    request_message = request.get_json()\n",
        "    response = index.query(request_message[\"message\"], llm = chat, verbose = True)\n",
        "    return jsonify({\"response\": response})"
      ],
      "metadata": {
        "id": "4O3wg4cSy1zE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OBnaX2Gy3Lx",
        "outputId": "56956cce-aa61-490a-8793-02539f4023f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://646f-34-73-75-241.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    }
  ]
}